{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:17:55.892022Z","iopub.execute_input":"2025-09-01T15:17:55.892639Z","iopub.status.idle":"2025-09-01T15:17:55.897855Z","shell.execute_reply.started":"2025-09-01T15:17:55.892611Z","shell.execute_reply":"2025-09-01T15:17:55.897193Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install -q datasets sentence-transformers faiss-cpu transformers nltk accelerate keybert[gensim] sentencepiece scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:17:55.898557Z","iopub.execute_input":"2025-09-01T15:17:55.898795Z","iopub.status.idle":"2025-09-01T15:17:59.447115Z","shell.execute_reply.started":"2025-09-01T15:17:55.898772Z","shell.execute_reply":"2025-09-01T15:17:59.446040Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os, sys, time, json\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom datasets import load_dataset\nimport numpy as np\nimport torch\nfrom sklearn.model_selection import train_test_split\n\n# NLP imports\nimport nltk\nnltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import stopwords\n\nfrom sentence_transformers import SentenceTransformer, CrossEncoder, util\nimport faiss\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, pipeline\nfrom keybert import KeyBERT\n\ndef log(message):\n    print(f\"[{time.strftime('%H:%M:%S')}] {message}\")\n\nlog(\"All imports successful!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:17:59.448352Z","iopub.execute_input":"2025-09-01T15:17:59.448650Z","iopub.status.idle":"2025-09-01T15:18:40.248462Z","shell.execute_reply.started":"2025-09-01T15:17:59.448619Z","shell.execute_reply":"2025-09-01T15:18:40.247825Z"}},"outputs":[{"name":"stderr","text":"2025-09-01 15:18:19.254030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756739899.608921      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756739899.709990      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[15:18:40] All imports successful!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n\nlog(\"Loading medical QA dataset...\")\n\ndataset = load_dataset(\"Malikeh1375/medical-question-answering-datasets\", name=\"all-processed\", split=\"train\")\nqa_data = [{\"question\": row[\"input\"], \"answer\": row[\"output\"]} for row in dataset]\n\ntrain_data, test_data = train_test_split(qa_data, test_size=0.2, random_state=42)\n\nlog(f\"Dataset loaded: {len(train_data)} train, {len(test_data)} test samples\")\nprint(\"Sample QA:\", train_data[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:18:40.250643Z","iopub.execute_input":"2025-09-01T15:18:40.251128Z","iopub.status.idle":"2025-09-01T15:18:53.542949Z","shell.execute_reply.started":"2025-09-01T15:18:40.251110Z","shell.execute_reply":"2025-09-01T15:18:53.542252Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nGPU name: Tesla T4\nGPU memory: 15.8GB\n[15:18:40] Loading medical QA dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b96b2c15318b4815b8d87f54432eae1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"all-processed/train-00000-of-00001-9bfe4(â€¦):   0%|          | 0.00/160M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eab8ec2737a4ef58fc0e90e6d981d61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/246678 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c542bf7247a40ee88f2652e548b81d7"}},"metadata":{}},{"name":"stdout","text":"[15:18:53] Dataset loaded: 197342 train, 49336 test samples\nSample QA: {'question': 'Dr., This is Himadri Dhar, my son Adriz is 3 years old and today around 4-5 hours ago we have taken cheese popcorn from outside stall and right now he is crying like anything for stomach pain. We are also suffering from gas formation. He does not have any other problem and not taking any other medicines at present. Can you please advise medicine for him?', 'answer': 'hi, welcome to chatbot. i see similar cases in my clinic every day. your child probably has food poisoning. if i was your treating doctor, i would have given syrup cyclops 5 ml po three times a day for 2 days and syrup zoxakind-o 3.5 ml po three times a day for 3 days. however since this is a prescription medicine, i advice you to meet the local doctor to confirm the diagnosis. also, avoid food from that stall to prevent similar problem in the future. i hope this has helped you. take care. regards - chatbot.'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\n# Sentence-window chunks for retrieval\ndef create_sentence_chunks(data, window_size=3, stride=1, min_chars=50):\n    chunks = []\n    for idx, item in enumerate(data):\n        text = item.get('answer') or item.get('text', '')\n        sentences = sent_tokenize(text)\n\n        if not sentences:\n            if len(text) > min_chars:\n                chunks.append({\"chunk\": text, \"source_idx\": idx})\n            continue\n\n        if len(sentences) <= window_size:\n            chunks.append({\"chunk\": \" \".join(sentences), \"source_idx\": idx})\n            continue\n\n        for i in range(0, max(1, len(sentences) - window_size + 1), stride):\n            chunk = \" \".join(sentences[i:i+window_size])\n            chunks.append({\"chunk\": chunk, \"source_idx\": idx})\n\n    return chunks\n\ntry:\n    sent_tokenize(\"This is a test sentence.\")\nexcept LookupError:\n    nltk.download('punkt_tab', quiet=True)\n    nltk.download('punkt', quiet=True)\n\nsentence_chunks = create_sentence_chunks(train_data, window_size=3, stride=1)\nlog(f\"Created {len(sentence_chunks)} sentence chunks\")\n\nEMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n\nlog(f\"Loading embedding model: {EMBED_MODEL}\")\nembedder = SentenceTransformer(EMBED_MODEL, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nchunk_texts = [chunk[\"chunk\"] for chunk in sentence_chunks]\nlog(\"Encoding chunks (this may take a while)...\")\nchunk_embeddings = embedder.encode(\n    chunk_texts,\n    normalize_embeddings=True,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    batch_size=32\n)\n\ndimension = chunk_embeddings.shape[1]\nindex = faiss.IndexFlatIP(dimension)\nindex.add(chunk_embeddings.astype(\"float32\"))\n\nlog(f\"FAISS index built with {index.ntotal} vectors, dimension: {dimension}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:18:53.543566Z","iopub.execute_input":"2025-09-01T15:18:53.543767Z","iopub.status.idle":"2025-09-01T15:28:02.285883Z","shell.execute_reply.started":"2025-09-01T15:18:53.543752Z","shell.execute_reply":"2025-09-01T15:28:02.285040Z"}},"outputs":[{"name":"stdout","text":"[15:19:08] Created 754364 sentence chunks\n[15:19:08] Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c96732f7c334aeea084516ebe05bdbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab0e7ad1bd46441a83ed924fb37c3397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"712daef821834f529842f216b73db3a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f89fc22a3b4659a634d6d5a78df014"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6af6ca80ad50494fb8c201fecbee0be6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83fa683ddde24e558b782fc814c4ade6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17a45bc7e3c84866bb4f43b65ef7bd68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ab4c18b07b419b9f0ad0c5b3643b24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a18d77a086c4197961cae13186c38f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf3885d4b5914a6f8a1ea82e2954f1ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d912102afdb54af6a825685906622501"}},"metadata":{}},{"name":"stdout","text":"[15:19:16] Encoding chunks (this may take a while)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/23574 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c2deff76584473e914df5c3afa967e4"}},"metadata":{}},{"name":"stdout","text":"[15:28:02] FAISS index built with 754364 vectors, dimension: 384\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"HYDE_MODEL = \"gpt2\"\n\nlog(f\"Loading HyDE model: {HYDE_MODEL}\")\nhyde_tokenizer = AutoTokenizer.from_pretrained(HYDE_MODEL)\nif hyde_tokenizer.pad_token is None:\n    hyde_tokenizer.pad_token = hyde_tokenizer.eos_token\n\nhyde_model = AutoModelForCausalLM.from_pretrained(HYDE_MODEL)\nhyde_model = hyde_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef get_hyde_answer(query, max_length=80):\n    prompt = f\"Question: {query}\\nAnswer:\"\n\n    inputs = hyde_tokenizer(\n        prompt,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=256\n    ).to(hyde_model.device if torch.cuda.is_available() else \"cpu\")\n\n    with torch.no_grad():\n        outputs = hyde_model.generate(\n            **inputs,\n            max_length=inputs['input_ids'].shape[1] + max_length,\n            do_sample=False,  # FIXED: Removed temperature/top_p\n            repetition_penalty=1.2,  # FIXED: Added to reduce repetition\n            pad_token_id=hyde_tokenizer.eos_token_id\n        )\n\n    text = hyde_tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return text.split(\"Answer:\")[-1].strip()\n\nlog(\"HyDE model loaded successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:28:02.286768Z","iopub.execute_input":"2025-09-01T15:28:02.287514Z","iopub.status.idle":"2025-09-01T15:28:06.163390Z","shell.execute_reply.started":"2025-09-01T15:28:02.287485Z","shell.execute_reply":"2025-09-01T15:28:06.162597Z"}},"outputs":[{"name":"stdout","text":"[15:28:02] Loading HyDE model: gpt2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7851f415e4e1417d8bae00d452f63fef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5f30517bad5427fadb8f222f9e96463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"688a91dbfbc84a10b6fd4f4d63ea3b7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f667976ae88c44caa1da05a9e680f8d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d95c5a659490477ea2fdb103b76be143"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b384d0cb63074d269a5c2f51540fd8f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"773de905eb18439db4c5371cfb19a081"}},"metadata":{}},{"name":"stdout","text":"[15:28:06] HyDE model loaded successfully\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"RERANKER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n\nlog(f\"Loading reranker: {RERANKER_MODEL}\")\nreranker = CrossEncoder(RERANKER_MODEL, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef retrieve_with_hyde(query, k=10):\n    hyde_answer = get_hyde_answer(query)\n    hyde_emb = embedder.encode([hyde_answer], normalize_embeddings=True, convert_to_numpy=True)\n    distances, indices = index.search(hyde_emb.astype(\"float32\"), k)\n    retrieved_chunks = [sentence_chunks[i][\"chunk\"] for i in indices[0]]\n    return retrieved_chunks, indices[0], distances[0]\n\ndef rerank_chunks(query, chunks, top_k=5):\n    if not chunks:\n        return []\n    pairs = [[query, chunk] for chunk in chunks]\n    scores = reranker.predict(pairs)\n    ranked_chunks = [chunk for _, chunk in sorted(zip(scores, chunks), key=lambda x: x[0], reverse=True)]\n    return ranked_chunks[:top_k]\n\nlog(\"Reranker loaded successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:28:06.164556Z","iopub.execute_input":"2025-09-01T15:28:06.164846Z","iopub.status.idle":"2025-09-01T15:28:08.662525Z","shell.execute_reply.started":"2025-09-01T15:28:06.164825Z","shell.execute_reply":"2025-09-01T15:28:08.661816Z"}},"outputs":[{"name":"stdout","text":"[15:28:06] Loading reranker: cross-encoder/ms-marco-MiniLM-L-6-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf61a79183f34ced836f5c6047c33f13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ea44bc6a8904819857b406441677a5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b8cad7d66374933a373017dbee5c3df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32d07db1c71a4e24a3dc6ec0448f01b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae7964c02d0470e956b5ebcfcb6b611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7456eddf9f4c4303a9c705782fc9d24d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ec267e5eeda451db75ecf4c3578d8e3"}},"metadata":{}},{"name":"stdout","text":"[15:28:08] Reranker loaded successfully\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"GEN_MODEL = \"microsoft/DialoGPT-medium\"\n\nlog(f\"Loading generation model: {GEN_MODEL}\")\ngen_tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL)\nif gen_tokenizer.pad_token is None:\n    gen_tokenizer.pad_token = gen_tokenizer.eos_token\n\ngen_model = AutoModelForCausalLM.from_pretrained(GEN_MODEL)\ngen_model = gen_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef generate_answer(query, context, max_new_tokens=100):\n    prompt = f\"\"\"Answer the question using the context provided.\n\nContext: {context}\n\nQuestion: {query}\n\nAnswer:\"\"\"\n\n    inputs = gen_tokenizer(\n        prompt,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=512\n    ).to(gen_model.device if torch.cuda.is_available() else \"cpu\")\n\n    with torch.no_grad():\n        outputs = gen_model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=False,  # FIXED: Removed temperature/top_p\n            pad_token_id=gen_tokenizer.eos_token_id\n        )\n\n    text = gen_tokenizer.decode(outputs[0], skip_special_tokens=True)\n    answer = text.split(\"Answer:\")[-1].strip()\n    return answer if answer else \"Unable to generate answer.\"  # FIXED: Handle empty output\n\nlog(\"Generation model loaded successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:28:08.663366Z","iopub.execute_input":"2025-09-01T15:28:08.663620Z","iopub.status.idle":"2025-09-01T15:28:16.447409Z","shell.execute_reply.started":"2025-09-01T15:28:08.663604Z","shell.execute_reply":"2025-09-01T15:28:16.446462Z"}},"outputs":[{"name":"stdout","text":"[15:28:08] Loading generation model: microsoft/DialoGPT-medium\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85fd5db36dd6438da06ecad14b187f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d5efd81a6ad4fca82d3dcc5c9b46a07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea899ef64d32405d98d54e64ffa9751f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82cf51a73418486c9735f88ab42059e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd0a4d6b9014c5fac35ca4ddfc9f12b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c51aea8ff0ec41a6ad59a220b7d8b0a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9daaf42c3f9460a81574e5eee136a98"}},"metadata":{}},{"name":"stdout","text":"[15:28:16] Generation model loaded successfully\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"kw_model = KeyBERT(model=embedder)\nSTOPWORDS = set(stopwords.words('english'))\n\ndef extract_keywords(text, top_n=8):\n    if not text or len(text.split()) < 3:\n        return []\n    keywords = kw_model.extract_keywords(\n        text,\n        keyphrase_ngram_range=(1, 2),\n        stop_words='english',\n        top_n=top_n\n    )\n    return [kw for kw, score in keywords]\n\ndef retrieval_relevance_score(query, top_k=5):\n    q_emb = embedder.encode([query], normalize_embeddings=True, convert_to_numpy=True)\n    distances, indices = index.search(q_emb.astype(\"float32\"), top_k)\n    scores = np.clip(distances[0], -1.0, 1.0)\n    similarity_scores = (scores + 1.0) / 2.0\n    return float(similarity_scores.mean())\n\ndef answer_completeness_score(answer, retrieved_chunks, sim_threshold=0.65):\n    all_facts = []\n    for chunk in retrieved_chunks:\n        facts = extract_keywords(chunk, top_n=4)\n        all_facts.extend(facts)\n\n    unique_facts = list(dict.fromkeys([f.lower() for f in all_facts if f]))\n    if not unique_facts:\n        return 0.0\n\n    answer_emb = embedder.encode([answer], normalize_embeddings=True, convert_to_numpy=True)\n    fact_embs = embedder.encode(unique_facts, normalize_embeddings=True, convert_to_numpy=True)\n\n    similarities = util.cos_sim(answer_emb, fact_embs).cpu().numpy()[0]\n    covered_facts = (similarities >= sim_threshold).sum()\n\n    return float(covered_facts / len(unique_facts))\n\ndef faithfulness_score(answer, context_chunks, sentence_threshold=0.5):\n    if not answer or not context_chunks:\n        return 0.0\n\n    answer_sentences = sent_tokenize(answer)\n    if not answer_sentences:\n        return 0.0\n\n    context_text = \"\\n\".join(context_chunks)\n    context_sentences = sent_tokenize(context_text)\n    if not context_sentences:\n        return 0.0\n\n    try:\n        answer_sentence_embeddings = embedder.encode(answer_sentences, normalize_embeddings=True, convert_to_numpy=True)\n        context_sentence_embeddings = embedder.encode(context_sentences, normalize_embeddings=True, convert_to_numpy=True)\n\n        similarity_matrix = util.cos_sim(answer_sentence_embeddings, context_sentence_embeddings).cpu().numpy()\n        max_similarities = np.max(similarity_matrix, axis=1)\n        faithful_sentences_count = (max_similarities >= sentence_threshold).sum()\n        score = faithful_sentences_count / len(answer_sentences)\n        return float(score)\n    except Exception as e:\n        log(f\"Error calculating faithfulness score: {e}\")\n        return 0.0\n\nlog(\"Evaluation metrics set up\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:28:16.448243Z","iopub.execute_input":"2025-09-01T15:28:16.448610Z","iopub.status.idle":"2025-09-01T15:28:16.543613Z","shell.execute_reply.started":"2025-09-01T15:28:16.448580Z","shell.execute_reply":"2025-09-01T15:28:16.539820Z"}},"outputs":[{"name":"stdout","text":"[15:28:16] Evaluation metrics set up\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def rag_pipeline_with_metrics(query, retrieve_k=10, rerank_k=5, context_chunks=3):\n    log(f\"Processing query: {query[:100]}...\")\n\n    retrieved_chunks, indices, distances = retrieve_with_hyde(query, k=retrieve_k)\n    reranked_chunks = rerank_chunks(query, retrieved_chunks, top_k=rerank_k)\n    context = \"\\n\\n\".join(reranked_chunks[:context_chunks])\n    answer = generate_answer(query, context)\n\n    retrieval_score = retrieval_relevance_score(query, top_k=retrieve_k)\n    completeness_score = answer_completeness_score(answer, reranked_chunks[:context_chunks])\n\n    context_emb = embedder.encode([context], normalize_embeddings=True, convert_to_numpy=True)\n    answer_emb = embedder.encode([answer], normalize_embeddings=True, convert_to_numpy=True)\n    faithfulness_score_val = float(util.cos_sim(context_emb, answer_emb).cpu().numpy()[0][0])\n\n    weights = {\"retrieval\": 0.4, \"completeness\": 0.3, \"faithfulness\": 0.3}\n    composite_score = (\n        weights[\"retrieval\"] * retrieval_score +\n        weights[\"completeness\"] * completeness_score +\n        weights[\"faithfulness\"] * faithfulness_score_val\n    )\n\n    return {\n        \"query\": query,\n        \"answer\": answer,\n        \"context\": reranked_chunks[:context_chunks],\n        \"retrieval_score\": retrieval_score,\n        \"completeness_score\": completeness_score,\n        \"faithfulness_score\": faithfulness_score_val,\n        \"composite_score\": composite_score,\n        \"hyde_answer\": get_hyde_answer(query)\n    }\n\nlog(\"Complete RAG pipeline ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:28:16.544712Z","iopub.execute_input":"2025-09-01T15:28:16.545030Z","iopub.status.idle":"2025-09-01T15:28:21.596269Z","shell.execute_reply.started":"2025-09-01T15:28:16.545004Z","shell.execute_reply":"2025-09-01T15:28:21.595423Z"}},"outputs":[{"name":"stdout","text":"[15:28:21] Complete RAG pipeline ready!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def test_pipeline():\n    test_queries = [\n      \"What is the MRC grading scale for muscle power?\"\n    ]\n\n    results = []\n    for query in test_queries:\n        try:\n            result = rag_pipeline_with_metrics(query)\n            results.append(result)\n\n            print(f\"\\n{'='*50}\")\n            print(f\"QUERY: {result['query']}\")\n            print(f\"\\nHyDE Answer: {result['hyde_answer'][:200]}...\")\n            print(f\"\\nGenerated Answer: {result['answer']}\")\n            print(f\"\\nScores:\")\n            print(f\"  Retrieval: {result['retrieval_score']:.3f}\")\n            print(f\"  Completeness: {result['completeness_score']:.3f}\")\n            print(f\"  Faithfulness: {result['faithfulness_score']:.3f}\")\n            print(f\"  Composite: {result['composite_score']:.3f}\")\n\n        except Exception as e:\n            print(f\"Error processing query '{query}': {e}\")\n\n    return results\n\ntest_results = test_pipeline()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:38:49.053784Z","iopub.execute_input":"2025-09-01T15:38:49.054138Z","iopub.status.idle":"2025-09-01T15:38:51.069286Z","shell.execute_reply.started":"2025-09-01T15:38:49.054105Z","shell.execute_reply":"2025-09-01T15:38:51.068473Z"}},"outputs":[{"name":"stdout","text":"[15:38:49] Processing query: What is the MRC grading scale for muscle power?...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3930e1670cbb4496bb3ad4235e01c69f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72e6469f0c33445484e883db3ea6254c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3cea1e27dc049a18f118ddda80edf01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c9b272be1a146a5b08a898acfa4a60f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03379462ae5d4e5eacfdf27f59af4a26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6d958ee10d44f7b2d0870c30dbf7e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b009e92f929c4ee6a31f76f2678a4b67"}},"metadata":{}},{"name":"stdout","text":"\n==================================================\nQUERY: What is the MRC grading scale for muscle power?\n\nHyDE Answer: The MRR (Muscle Power Rating Scale) was developed by Dr. Robert J. Hirsch, MD and has been used to evaluate strength in men with muscular dystrophy since its inception as a clinical trial of anabolic ...\n\nGenerated Answer: Unable to generate answer.\n\nScores:\n  Retrieval: 0.750\n  Completeness: 0.000\n  Faithfulness: 0.001\n  Composite: 0.300\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"q = \"What is the MRC grading scale for muscle power?\"\nlog(\"Running pipeline (this may take a while on first load)...\")\nresult = rag_pipeline_with_metrics(q, retrieve_k=10, rerank_k=5, context_chunks=3)\nprint(\"\\n=== RESULT ===\")\nprint(\"Query:\", result[\"query\"])\nprint(\"\\nContext (top chunks):\")\nfor c in result[\"context\"]:\n    print(\"-\", c[:300].replace(\"\\n\", \" \"), \"...\")\nprint(\"\\nGenerated Answer:\\n\", result[\"answer\"])\nprint(\"\\nScores: Retrieval=%.3f, Completeness=%.3f, Faithfulness=%.3f, Composite=%.3f\" % (\n    result[\"retrieval_score\"], result[\"completeness_score\"], result[\"faithfulness_score\"], result[\"composite_score\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:38:51.070259Z","iopub.execute_input":"2025-09-01T15:38:51.070517Z","iopub.status.idle":"2025-09-01T15:38:53.102467Z","shell.execute_reply.started":"2025-09-01T15:38:51.070500Z","shell.execute_reply":"2025-09-01T15:38:53.101853Z"}},"outputs":[{"name":"stdout","text":"[15:38:51] Running pipeline (this may take a while on first load)...\n[15:38:51] Processing query: What is the MRC grading scale for muscle power?...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147befefbe504f248448ce4f8a9b1933"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2e95afcd5994daf9e6ceb1278f95c0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01a9b5d79e69434ba38a5d8c680d2b25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9d3402af6514b759698d5183732b47f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcea4ccb109f443eba64262639515121"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27de9e8c2c624c288a6b7475696f2eae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"705d0471cda24e60a4bc8673ae50ceb7"}},"metadata":{}},{"name":"stdout","text":"\n=== RESULT ===\nQuery: What is the MRC grading scale for muscle power?\n\nContext (top chunks):\n- Muscle strength and force development in high- and low-functioning elderly men: Influence of muscular and neural factors. ...\n- The gold standard diagnostic test for Duchenne muscular dystrophy is genetic studies. This involves analyzing the patient's DNA for mutations in the dystrophin gene, which is responsible for producing a protein essential for muscle function. Duchenne muscular dystrophy is a genetic disorder that pri ...\n- hi, thank you for providing the brief history of you. a thorough neuromuscular assessment is advised. based on the assessment the muscular strength will be determined, also an mri will help us determine the status of the soft tissue injury. ...\n\nGenerated Answer:\n Unable to generate answer.\n\nScores: Retrieval=0.750, Completeness=0.000, Faithfulness=0.001, Composite=0.300\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def evaluate_on_testset(test_data, sample_size=10):\n    log(f\"Evaluating on {sample_size} test samples...\")\n\n    results = []\n    for i, sample in enumerate(test_data[:sample_size]):\n        try:\n            result = rag_pipeline_with_metrics(sample['question'])\n            result['ground_truth'] = sample['answer']\n            results.append(result)\n\n            if (i + 1) % 5 == 0:\n                log(f\"Processed {i + 1}/{sample_size} samples\")\n\n        except RuntimeError as e:\n            if \"device-side assert triggered\" in str(e):\n                log(f\"Skipping sample {i} due to CUDA error: {e}\")\n                continue\n            else:\n                log(f\"Error on sample {i}: {e}\")\n                continue\n        except Exception as e:\n            log(f\"Error on sample {i}: {e}\")\n            continue\n\n    if results:\n        avg_retrieval = np.mean([r['retrieval_score'] for r in results])\n        avg_completeness = np.mean([r['completeness_score'] for r in results])\n        avg_faithfulness = np.mean([r['faithfulness_score'] for r in results])\n        avg_composite = np.mean([r['composite_score'] for r in results])\n\n        print(f\"\\n{'='*50}\")\n        print(\"EVALUATION RESULTS:\")\n        print(f\"Average Retrieval Score: {avg_retrieval:.3f}\")\n        print(f\"Average Completeness Score: {avg_completeness:.3f}\")\n        print(f\"Average Faithfulness Score: {avg_faithfulness:.3f}\")\n        print(f\"Average Composite Score: {avg_composite:.3f}\")\n        print(f\"Total samples processed: {len(results)}\")\n\n    return results\n\neval_results = evaluate_on_testset(test_data, sample_size=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T15:28:27.725053Z","iopub.execute_input":"2025-09-01T15:28:27.725257Z","iopub.status.idle":"2025-09-01T15:28:47.657148Z","shell.execute_reply.started":"2025-09-01T15:28:27.725242Z","shell.execute_reply":"2025-09-01T15:28:47.656298Z"}},"outputs":[{"name":"stdout","text":"[15:28:27] Evaluating on 10 test samples...\n[15:28:27] Processing query: my husband has hepatitis c but the liver biopsy was good. 0, 0, 1 I believe.  he is taking high dose...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74a973964ec946f4847dd20723c958fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41deea4f439f4073b83e7d390840c9f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fa8b7bf00ef4db3bfc52b15428c6dc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f2f598838d4b98b04695701e0ff0e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b05c9dea5344188aac054dea6663e6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23f64c03f71246cfad5cc658003e182e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9052556b6d441908baf1c89b481fd08"}},"metadata":{}},{"name":"stdout","text":"[15:28:29] Processing query: Mina and Andersen, authors of the Perspectives in Science: COVID-19 Testing: One Size Does Not Fit A...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f68e245a32434437a91b7e6ac277a3e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63015f1eab504984b81b5b3de515bf11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3355e165ac19437ca285c275e8990f34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aad0576ec3b4750b1357f9b0fec7d5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aaaee41a90044a5877849f042d46934"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"813cce752716472e9eea4bbd9465ea11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88d020adb2154df2a12b11fdc384ac16"}},"metadata":{}},{"name":"stdout","text":"[15:28:32] Processing query: Q:A 2-month-old is brought to the physician for a well-child examination. She was born at 39 weeks g...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f63f4746a85d4906948024c7e284032c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6aa257615a54bf2a7bf33b4fc50a4c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1939d48d1df14499bb779f5e4f53cd65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a08d3706bb4ba49d5dc20bcb26be79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e6d9c3d7417470baa206e9cc8cf5d5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78e259ac9b8441138d97969ecbfe2a07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7471b29174f4f8bbc5e4817d345b663"}},"metadata":{}},{"name":"stdout","text":"[15:28:34] Processing query: My grandmmother is 81 yrs old. Checked her bp several times over a 3hr period and always got 190/90....\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65b9df3941bf490b934baa316e35dd8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3f165a75f9a41fe945fb6ad333f37a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f533086d92d4950b63bd42ac76d79ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c544a9fd6ba64f5ebd1d4b30af757d2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"111480d61f3945efaad71d6ebfb3454b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d166957626934971a834f52be135028f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3a07477d38f4618a4af93c514a4aaba"}},"metadata":{}},{"name":"stdout","text":"[15:28:36] Processing query: What are the two main functions of the Vestibulocochlear nerve (CN VIII)?...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b5003b8eb214f598e47fb276e59df94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d260a99763214452a8c7eba9d00025ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf223be3fc9f4a16b7b1edc3b06f0ffc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c9ddfb00904107bb57cfca7ad8ba9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf79a875dd654355b4bf95c04c1bbb1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aa82659fbee4892bab91014886d35fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a36357daa40345229103baa7dd23f862"}},"metadata":{}},{"name":"stdout","text":"[15:28:38] Processed 5/10 samples\n[15:28:38] Processing query: Background and importanceA greater benefit was suggested with early treatment with remdesivir agains...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1c9a56a301c452596f6f8fbaf07ef70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d009b50d89b48eba4f790529c667f97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8fdc0b1e73e4ec8874bbd0bb280758d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"006a3dfedc7642dcb933af9e8f503626"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8acef41d6dab46b8aab03aaf46af8676"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8060011596848f6a2123093652e29cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b27f513e6648e798cd160b8cd24a1c"}},"metadata":{}},{"name":"stdout","text":"[15:28:39] Processing query: Hello doctor,I have a few bumps on my penis skin. I do masturbate. I am concerned because I do not k...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b68ad24a90294b0c85bb2a5410ced4c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11b1715c9af945f49dba8ea792ca1f71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed883d6f962c4dc2bcd39b08c8932b57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f7446b4d7ce4ba59801d82bd1aed01c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da4f7a0573144e3ea7c8ad9e675e6830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46dfd6f65cdf4bc59da7c482d2fd556d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"335f93416f124c04a1c5b34627404af0"}},"metadata":{}},{"name":"stdout","text":"[15:28:41] Processing query: my husband had throat cancer in 2004, hes had 2 mri an cat scan an bone scan, now the suregon saying...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94d7f546733d43648ae104b28a22d7e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dea6081eb6cc43a399c6af194282df9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12485a0efcf24bd18b34908994974481"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4982a13691249b29047a6f212574f84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c90073b6c141c4aef6266ae9be9cc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7787b04161241feb1db38612e921a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92980ca8eea94cfc870b8df70ccc0f23"}},"metadata":{}},{"name":"stdout","text":"[15:28:43] Processing query: What medical condition is suggested by the presence of headache, systemic symptoms such as fever or ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"542f332411924129a8ec299bfb7f2aae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98e57ec66c9749d8b2ed2deda98b2d6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d99948ffc3e4c29b568bee42b8c58cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076392f8b5ad4b0984374f8bce95f104"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38df3c7330ba417c8c49087aae70ab30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a6579eac6bf4a71aa981f9f6d5d3ca9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad4f44ab51a34810aa37df0af5638020"}},"metadata":{}},{"name":"stdout","text":"[15:28:45] Processing query:  Glaucoma Open-angle glaucoma Chronic glaucoma Chronic open-angle glaucoma Primary open-angle glauco...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e46b0eda1b83405690ed23c065f12f4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b846307a53f34d44b1d3d1ffb1c6d05f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2ebe99d949b4f99878dfae103dddd3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3696090978294c7181d719ef2c23fe33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a0125eb58494fa59bbc9cf7fbcd04d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"522d299460554f1fa720ec75302f7f15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fcf739b6df74054982d7f86297dd0fe"}},"metadata":{}},{"name":"stdout","text":"[15:28:47] Processed 10/10 samples\n\n==================================================\nEVALUATION RESULTS:\nAverage Retrieval Score: 0.848\nAverage Completeness Score: 0.062\nAverage Faithfulness Score: 0.205\nAverage Composite Score: 0.419\nTotal samples processed: 10\n","output_type":"stream"}],"execution_count":15}]}